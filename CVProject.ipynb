{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xws7yfjPF3l3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import random\n",
        "\n",
        "class UncertaintyAugmentation(object):\n",
        "    \"\"\"Add uncertainty through various augmentations\"\"\"\n",
        "    def __init__(self, noise_level=0.1, occlusion_prob=0.2, blur_prob=0.2):\n",
        "        self.noise_level = noise_level\n",
        "        self.occlusion_prob = occlusion_prob\n",
        "        self.blur_prob = blur_prob\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        \"\"\"Apply transformations to either a dictionary with 'image' key or directly to a PIL/tensor image\"\"\"\n",
        "        # Check if the sample is a dictionary with 'image' key or directly an image\n",
        "        if isinstance(sample, dict) and 'image' in sample:\n",
        "            image = sample['image']\n",
        "            is_dict = True\n",
        "        else:\n",
        "            image = sample\n",
        "            is_dict = False\n",
        "\n",
        "        # Convert PIL Image to tensor if needed\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = transforms.ToTensor()(image)\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        if random.random() < 0.5:\n",
        "            noise = torch.randn_like(image) * self.noise_level\n",
        "            image = image + noise\n",
        "            image = torch.clamp(image, 0, 1)\n",
        "\n",
        "        # Add random occlusion\n",
        "        if random.random() < self.occlusion_prob:\n",
        "            h, w = image.shape[-2:]\n",
        "\n",
        "            # Create random rectangle for occlusion\n",
        "            occlusion_width = random.randint(w // 10, w // 3)\n",
        "            occlusion_height = random.randint(h // 10, h // 3)\n",
        "            x = random.randint(0, w - occlusion_width)\n",
        "            y = random.randint(0, h - occlusion_height)\n",
        "\n",
        "            # Apply occlusion\n",
        "            image[:, y:y+occlusion_height, x:x+occlusion_width] = 0\n",
        "\n",
        "        # Add blur effect\n",
        "        if random.random() < self.blur_prob and isinstance(image, torch.Tensor):\n",
        "            # Convert to PIL for Gaussian blur\n",
        "            to_pil = transforms.ToPILImage()\n",
        "            to_tensor = transforms.ToTensor()\n",
        "\n",
        "            # Convert tensor to PIL\n",
        "            pil_image = to_pil(image)\n",
        "\n",
        "            # Apply Gaussian blur\n",
        "            blurred = transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0))(pil_image)\n",
        "\n",
        "            # Convert back to tensor\n",
        "            image = to_tensor(blurred)\n",
        "\n",
        "        # Return in the same format as received\n",
        "        if is_dict:\n",
        "            sample['image'] = image\n",
        "            return sample\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "\n",
        "class VehicularPerceptionDataset(data.Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_training=True, num_vehicles=5, adversarial_prob=0.0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with images\n",
        "            transform (callable, optional): Optional transform to be applied on samples\n",
        "            is_training (bool): Whether this is for training or validation\n",
        "            num_vehicles (int): Number of vehicles in collaborative perception\n",
        "            adversarial_prob (float): Probability of generating adversarial samples during training\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.is_training = is_training\n",
        "        self.num_vehicles = num_vehicles\n",
        "        self.adversarial_prob = adversarial_prob\n",
        "\n",
        "        # Define default transforms if none provided\n",
        "        if transform is None:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((128, 128)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transform\n",
        "\n",
        "        self.samples = self._load_samples()\n",
        "\n",
        "    def _load_samples(self):\n",
        "        \"\"\"Load sample paths from Google Drive image directory\"\"\"\n",
        "        samples = []\n",
        "\n",
        "        # Verify Google Drive is mounted\n",
        "        if not os.path.exists('/content/drive'):\n",
        "            # Try to mount Google Drive if not already mounted\n",
        "            try:\n",
        "                from google.colab import drive\n",
        "                drive.mount('/content/drive')\n",
        "                print(\"Google Drive mounted successfully\")\n",
        "            except:\n",
        "                raise RuntimeError(\"Failed to mount Google Drive. Please run 'from google.colab import drive; drive.mount('/content/drive')' first\")\n",
        "\n",
        "        # Check if specific directory exists in Google Drive\n",
        "        if not os.path.exists(self.root_dir):\n",
        "            raise FileNotFoundError(f\"Dataset directory {self.root_dir} not found in Google Drive\")\n",
        "\n",
        "        # Find all image files\n",
        "        valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "\n",
        "        try:\n",
        "            image_files = [f for f in os.listdir(self.root_dir)\n",
        "                          if os.path.isfile(os.path.join(self.root_dir, f)) and\n",
        "                          any(f.lower().endswith(ext) for ext in valid_extensions)]\n",
        "\n",
        "            print(f\"Found {len(image_files)} images in {self.root_dir}\")\n",
        "\n",
        "            # Create sample entries\n",
        "            for img_name in image_files:\n",
        "                img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "                # Create a simple sample entry without annotations\n",
        "                sample = {\n",
        "                    'image_path': img_path,\n",
        "                    'vehicle_id': 0,  # Main ego vehicle\n",
        "                    'frame_id': img_name.split('.')[0]  # Use filename as frame ID\n",
        "                }\n",
        "\n",
        "                samples.append(sample)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing files in Google Drive: {e}\")\n",
        "            raise\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image data\n",
        "        sample_info = self.samples[idx]\n",
        "        image_path = sample_info['image_path']\n",
        "\n",
        "        try:\n",
        "            # Load the image using PIL\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            # Apply transformations directly to the PIL image\n",
        "            if self.transform:\n",
        "                image_tensor = self.transform(image)  # This should now work with either transform type\n",
        "            else:\n",
        "                # Default transformation if none provided\n",
        "                image_tensor = transforms.ToTensor()(image)\n",
        "\n",
        "            # Create the base sample\n",
        "            sample = {\n",
        "                'image': image_tensor,\n",
        "                'vehicle_id': sample_info['vehicle_id'],\n",
        "                'frame_id': sample_info['frame_id']\n",
        "            }\n",
        "\n",
        "            # For collaborative perception, simulate data from multiple vehicles\n",
        "            if self.num_vehicles > 1:\n",
        "                vehicle_images = [image_tensor]  # Start with the ego vehicle's image\n",
        "\n",
        "                # Generate simulated views from other vehicles\n",
        "                for v in range(1, self.num_vehicles):\n",
        "                    # Apply random transformation to simulate different viewpoint\n",
        "                    vehicle_image = self._simulate_vehicle_view(image_tensor, v)\n",
        "\n",
        "                    # Add adversarial perturbation with specified probability during training\n",
        "                    if self.is_training and random.random() < self.adversarial_prob:\n",
        "                        vehicle_image = self._apply_adversarial_perturbation(vehicle_image)\n",
        "                        sample[f'vehicle_{v}_is_adversarial'] = torch.tensor([1.0])\n",
        "                    else:\n",
        "                        sample[f'vehicle_{v}_is_adversarial'] = torch.tensor([0.0])\n",
        "\n",
        "                    vehicle_images.append(vehicle_image)\n",
        "\n",
        "                sample['vehicle_images'] = vehicle_images\n",
        "\n",
        "            return sample\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {image_path}: {e}\")\n",
        "            # Return a default sample in case of error\n",
        "            return self.__getitem__((idx + 1) % len(self.samples))\n",
        "\n",
        "    def _simulate_vehicle_view(self, image_tensor, vehicle_id):\n",
        "      \"\"\"Simulate different viewpoints from other vehicles with padding\"\"\"\n",
        "      # Apply random transformations to simulate different viewpoints\n",
        "\n",
        "      # Create a random affine transformation\n",
        "      angle = random.uniform(-15, 15)\n",
        "      translate = (random.uniform(-0.1, 0.1), random.uniform(-0.1, 0.1))\n",
        "      scale = random.uniform(0.9, 1.1)\n",
        "\n",
        "      # Convert tensor back to PIL for transformation\n",
        "      to_pil = transforms.ToPILImage()\n",
        "      to_tensor = transforms.ToTensor()\n",
        "      normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "\n",
        "      # If the tensor is normalized, denormalize it first\n",
        "      if image_tensor.min() < 0:\n",
        "          pil_image = to_pil(image_tensor * 0.5 + 0.5)  # Denormalize\n",
        "      else:\n",
        "          pil_image = to_pil(image_tensor)\n",
        "\n",
        "      # Create a padded image with gray background\n",
        "      width, height = pil_image.size\n",
        "      padded_image = Image.new('RGB', (int(width * 1.2), int(height * 1.2)), (128, 128, 128))\n",
        "      padded_image.paste(pil_image, (int(width * 0.1), int(height * 0.1)))\n",
        "\n",
        "      # Apply the transformation without fillcolor\n",
        "      transformed = transforms.functional.affine(\n",
        "          padded_image, angle, translate, scale, 0\n",
        "      )\n",
        "\n",
        "      # Crop back to original size\n",
        "      transformed = transforms.CenterCrop((height, width))(transformed)\n",
        "\n",
        "      # Convert back to tensor and normalize if the original was normalized\n",
        "      transformed_tensor = to_tensor(transformed)\n",
        "      if image_tensor.min() < 0:\n",
        "          transformed_tensor = normalize(transformed_tensor)\n",
        "\n",
        "      return transformed_tensor\n",
        "\n",
        "    def _apply_adversarial_perturbation(self, image_tensor, magnitude=0.1):\n",
        "        \"\"\"Apply adversarial perturbation to the image\"\"\"\n",
        "        # Simple implementation: add random noise\n",
        "        noise = torch.randn_like(image_tensor) * magnitude\n",
        "\n",
        "        # Check if tensor is normalized\n",
        "        if image_tensor.min() < 0:\n",
        "            # For normalized images (-1 to 1 range)\n",
        "            perturbed_image = image_tensor + noise\n",
        "            perturbed_image = torch.clamp(perturbed_image, -1, 1)\n",
        "        else:\n",
        "            # For standard images (0 to 1 range)\n",
        "            perturbed_image = image_tensor + noise\n",
        "            perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "        return perturbed_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class FeatureCompressionVAE(nn.Module):\n",
        "    def __init__(self, input_channels=3, latent_dim=64):\n",
        "        super(FeatureCompressionVAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=4, stride=2, padding=1),  # 64x64\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # 32x32\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 16x16\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # 8x8\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        # Calculate flattened feature size\n",
        "        self.feature_size = 256 * 8 * 8\n",
        "\n",
        "        # Mean and variance layers\n",
        "        self.fc_mu = nn.Linear(self.feature_size, latent_dim)\n",
        "        self.fc_var = nn.Linear(self.feature_size, latent_dim)\n",
        "\n",
        "        # Decoder input\n",
        "        self.decoder_input = nn.Linear(latent_dim, self.feature_size)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 16x16\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 32x32\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # 64x64\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(32, input_channels, kernel_size=4, stride=2, padding=1),  # 128x128\n",
        "            nn.Tanh()  # Output normalized between -1 and 1\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        # Encode the input\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(-1, self.feature_size)\n",
        "\n",
        "        # Get latent distribution parameters\n",
        "        mu = self.fc_mu(x)\n",
        "        log_var = self.fc_var(x)\n",
        "\n",
        "        return mu, log_var\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        # Reparameterization trick\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        # Decode from latent space\n",
        "        x = self.decoder_input(z)\n",
        "        x = x.view(-1, 256, 8, 8)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        mu, log_var = self.encode(x)\n",
        "\n",
        "        # Get latent vector through reparameterization\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "\n",
        "        # Feature selection - keep top-k features based on importance\n",
        "        importance = torch.abs(z)\n",
        "        k = int(0.7 * z.size(1))  # Keep 70% of features (adjust as needed)\n",
        "        _, indices = torch.topk(importance, k=k, dim=1)\n",
        "\n",
        "        # Create sparse latent representation - set non-top-k values to zero\n",
        "        batch_size = z.size(0)\n",
        "        z_sparse = torch.zeros_like(z)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            z_sparse[i, indices[i]] = z[i, indices[i]]\n",
        "\n",
        "        # Decode\n",
        "        reconstructed = self.decode(z_sparse)\n",
        "\n",
        "        return reconstructed, mu, log_var, z_sparse\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, log_var, kld_weight=0.005):\n",
        "        \"\"\"\n",
        "        Calculate VAE loss with reconstruction and KL divergence terms\n",
        "        \"\"\"\n",
        "        # Reconstruction loss (using MSE for image data)\n",
        "        recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
        "\n",
        "        # KL divergence loss\n",
        "        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "        # Total loss\n",
        "        loss = recon_loss + kld_weight * kld_loss\n",
        "\n",
        "        return loss, recon_loss, kld_loss"
      ],
      "metadata": {
        "id": "bdRDcrWiH6yE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class DiffusionModel(nn.Module):\n",
        "    def __init__(self, feature_dim=64, timesteps=100):\n",
        "        super(DiffusionModel, self).__init__()\n",
        "        self.feature_dim = feature_dim\n",
        "        self.timesteps = timesteps\n",
        "\n",
        "        # Define noise predictor network\n",
        "        self.noise_predictor = nn.Sequential(\n",
        "            nn.Linear(feature_dim + 1, 128),  # +1 for time embedding\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(128, feature_dim)\n",
        "        )\n",
        "\n",
        "        # Define beta schedule (noise level at each timestep)\n",
        "        self.beta = self._cosine_beta_schedule()\n",
        "        self.alpha = 1. - self.beta\n",
        "        self.alpha_cumprod = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "    def _cosine_beta_schedule(self):\n",
        "        \"\"\"\n",
        "        Cosine beta schedule for diffusion process - smoother noise addition\n",
        "        \"\"\"\n",
        "        steps = self.timesteps + 1\n",
        "        x = torch.linspace(0, self.timesteps, steps)\n",
        "        alphas_cumprod = torch.cos(((x / self.timesteps) + 0.008) / 1.008 * torch.pi * 0.5) ** 2\n",
        "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "        return torch.clip(betas, 0.0001, 0.9999)\n",
        "\n",
        "    def add_noise(self, x, t):\n",
        "        \"\"\"\n",
        "        Add noise to features based on diffusion process at timestep t\n",
        "        \"\"\"\n",
        "        # Get noise scaling for timestep t\n",
        "        # Move alpha_cumprod to the same device as t\n",
        "        a_t = self.alpha_cumprod.to(t.device)[t]\n",
        "\n",
        "        # Expand dimensions for proper broadcasting\n",
        "        a_t = a_t.reshape(-1, 1)\n",
        "\n",
        "        # Generate random noise\n",
        "        noise = torch.randn_like(x)\n",
        "\n",
        "        # Apply noise based on diffusion equation: x_t = sqrt(a_t) * x_0 + sqrt(1-a_t) * Îµ\n",
        "        noisy_x = torch.sqrt(a_t) * x + torch.sqrt(1 - a_t) * noise\n",
        "\n",
        "        return noisy_x, noise\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        \"\"\"\n",
        "        Forward pass to predict noise at timestep t\n",
        "        \"\"\"\n",
        "        # Time embedding (normalized)\n",
        "        t_emb = t.float() / self.timesteps\n",
        "        t_emb = t_emb.reshape(-1, 1)\n",
        "\n",
        "        # Concat input with time embedding\n",
        "        x_t = torch.cat([x, t_emb], dim=1)\n",
        "\n",
        "        # Predict noise\n",
        "        predicted_noise = self.noise_predictor(x_t)\n",
        "\n",
        "        return predicted_noise\n",
        "\n",
        "    def sample(self, shape, device, steps=None):\n",
        "        \"\"\"\n",
        "        Generate new features from noise using reverse diffusion\n",
        "        \"\"\"\n",
        "        if steps is None:\n",
        "            steps = self.timesteps\n",
        "\n",
        "        # Start from pure noise\n",
        "        x = torch.randn(shape).to(device)\n",
        "\n",
        "        # Reverse diffusion process (denoise step by step)\n",
        "        for t in range(steps - 1, -1, -1):\n",
        "            t_tensor = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
        "\n",
        "            # No gradient needed for sampling\n",
        "            with torch.no_grad():\n",
        "                # Get current time step beta\n",
        "                beta_t = self.beta[t]\n",
        "\n",
        "                # Predict noise\n",
        "                predicted_noise = self.forward(x, t_tensor)\n",
        "\n",
        "                # No noise for final step\n",
        "                if t > 0:\n",
        "                    noise = torch.randn_like(x)\n",
        "                else:\n",
        "                    noise = 0\n",
        "\n",
        "                # Update x based on reverse diffusion equation\n",
        "                x = (1 / torch.sqrt(1 - beta_t)) * (x - (beta_t / torch.sqrt(1 - self.alpha_cumprod[t])) * predicted_noise) + torch.sqrt(beta_t) * noise\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "inkfjsFaH9jC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Import the models and dataset\n",
        "# Make sure these classes are defined in your project\n",
        "# from models.feature_compression import FeatureCompressionVAE\n",
        "# from models.diffusion import DiffusionModel\n",
        "# from data.dataset import VehicularPerceptionDataset, UncertaintyAugmentation\n",
        "\n",
        "def train_adversarial_defense_system():\n",
        "    \"\"\"\n",
        "    Complete training function for the adversarial defense system\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    class Config:\n",
        "        # Paths\n",
        "        data_dir = '/content/drive/MyDrive/CVProject/'\n",
        "        output_dir = '/content/drive/MyDrive/CVProject/output/'\n",
        "\n",
        "        # Model parameters\n",
        "        input_channels = 3\n",
        "        image_size = 128\n",
        "        latent_dim = 64\n",
        "        num_vehicles = 5\n",
        "        diffusion_timesteps = 100\n",
        "\n",
        "        # Training parameters\n",
        "        batch_size = 8\n",
        "        num_workers = 2\n",
        "        num_epochs = 50\n",
        "        lr = 1e-4\n",
        "        beta1 = 0.9\n",
        "        beta2 = 0.999\n",
        "\n",
        "        # Loss parameters\n",
        "        kld_weight = 0.005  # Weight for KL divergence in VAE loss\n",
        "\n",
        "        # Adversarial parameters\n",
        "        adversarial_prob = 0.3  # Probability of generating adversarial samples\n",
        "        adversarial_magnitude = 0.2  # Magnitude of adversarial perturbation\n",
        "\n",
        "        # Save parameters\n",
        "        save_interval = 5  # Save checkpoint every N epochs\n",
        "\n",
        "        # Device settings\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Set random seed for reproducibility\n",
        "        seed = 42\n",
        "\n",
        "    config = Config()\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(config.output_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(config.output_dir, 'logs'), exist_ok=True)\n",
        "\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(config.seed)\n",
        "    np.random.seed(config.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config.seed)\n",
        "\n",
        "    print(f\"Using device: {config.device}\")\n",
        "\n",
        "    # Initialize tensorboard for tracking\n",
        "    writer = SummaryWriter(log_dir=os.path.join(config.output_dir, 'logs'))\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    # First define the transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((config.image_size, config.image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "        UncertaintyAugmentation(noise_level=0.1, occlusion_prob=0.2, blur_prob=0.2)\n",
        "    ])\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = VehicularPerceptionDataset(\n",
        "        root_dir=config.data_dir,\n",
        "        transform=transform,\n",
        "        is_training=True,\n",
        "        num_vehicles=config.num_vehicles,\n",
        "        adversarial_prob=config.adversarial_prob\n",
        "    )\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    print(f\"Dataset created with {len(dataset)} images, {config.num_vehicles} simulated vehicles\")\n",
        "\n",
        "    # Initialize models\n",
        "    # 1. Variational Autoencoder for feature compression\n",
        "    vae = FeatureCompressionVAE(\n",
        "        input_channels=config.input_channels,\n",
        "        latent_dim=config.latent_dim\n",
        "    ).to(config.device)\n",
        "\n",
        "    # 2. Diffusion model for uncertainty modeling\n",
        "    diffusion = DiffusionModel(\n",
        "        feature_dim=config.latent_dim,\n",
        "        timesteps=config.diffusion_timesteps\n",
        "    ).to(config.device)\n",
        "\n",
        "    # Initialize optimizers\n",
        "    vae_optimizer = optim.Adam(\n",
        "        vae.parameters(),\n",
        "        lr=config.lr,\n",
        "        betas=(config.beta1, config.beta2)\n",
        "    )\n",
        "\n",
        "    diffusion_optimizer = optim.Adam(\n",
        "        diffusion.parameters(),\n",
        "        lr=config.lr,\n",
        "        betas=(config.beta1, config.beta2)\n",
        "    )\n",
        "\n",
        "    # Create learning rate schedulers (optional but helpful)\n",
        "    vae_scheduler = optim.lr_scheduler.StepLR(vae_optimizer, step_size=10, gamma=0.5)\n",
        "    diffusion_scheduler = optim.lr_scheduler.StepLR(diffusion_optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Starting training...\")\n",
        "    global_step = 0\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        vae.train()\n",
        "        diffusion.train()\n",
        "\n",
        "        # Track losses for this epoch\n",
        "        epoch_vae_loss = 0.0\n",
        "        epoch_diffusion_loss = 0.0\n",
        "        epoch_recon_loss = 0.0\n",
        "        epoch_kld_loss = 0.0\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Process each batch\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.num_epochs}\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(progress_bar):\n",
        "            # Process vehicle images\n",
        "            if 'vehicle_images' in batch:\n",
        "                # Get all vehicle images\n",
        "                all_vehicle_images = batch['vehicle_images']\n",
        "                batch_size = all_vehicle_images[0].shape[0]\n",
        "\n",
        "                # Move to device (GPU if available)\n",
        "                vehicle_images = [img.to(config.device) for img in all_vehicle_images]\n",
        "\n",
        "                # 1. Train VAE with ego vehicle images (clean reference)\n",
        "                vae_optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass through VAE\n",
        "                ego_images = vehicle_images[0]  # Main vehicle (non-adversarial)\n",
        "                recon_images, mu, log_var, z_sparse = vae(ego_images)\n",
        "\n",
        "                # Calculate VAE loss components\n",
        "                vae_loss, recon_loss, kld_loss = vae.loss_function(\n",
        "                    recon_images, ego_images, mu, log_var, kld_weight=config.kld_weight\n",
        "                )\n",
        "\n",
        "                # Backward pass and optimize VAE\n",
        "                vae_loss.backward()\n",
        "                vae_optimizer.step()\n",
        "\n",
        "                # 2. Train Diffusion model with latent vectors\n",
        "                diffusion_optimizer.zero_grad()\n",
        "\n",
        "                # Sample random timestep\n",
        "                t = torch.randint(0, config.diffusion_timesteps, (batch_size,), device=config.device)\n",
        "\n",
        "                # Add noise to latent vector according to timestep\n",
        "                noisy_z, noise = diffusion.add_noise(z_sparse.detach(), t)\n",
        "\n",
        "                # Predict noise with diffusion model\n",
        "                predicted_noise = diffusion(noisy_z, t)\n",
        "\n",
        "                # Calculate diffusion loss (noise prediction MSE)\n",
        "                diffusion_loss = torch.nn.functional.mse_loss(predicted_noise, noise)\n",
        "\n",
        "                # Backward pass and optimize diffusion model\n",
        "                diffusion_loss.backward()\n",
        "                diffusion_optimizer.step()\n",
        "\n",
        "                # Track losses\n",
        "                epoch_vae_loss += vae_loss.item()\n",
        "                epoch_recon_loss += recon_loss.item()\n",
        "                epoch_kld_loss += kld_loss.item()\n",
        "                epoch_diffusion_loss += diffusion_loss.item()\n",
        "\n",
        "                # Update progress bar\n",
        "                progress_bar.set_postfix({\n",
        "                    'VAE Loss': f\"{vae_loss.item():.4f}\",\n",
        "                    'Diff Loss': f\"{diffusion_loss.item():.4f}\"\n",
        "                })\n",
        "\n",
        "                # Log metrics to tensorboard\n",
        "                writer.add_scalar('Loss/VAE_Total', vae_loss.item(), global_step)\n",
        "                writer.add_scalar('Loss/VAE_Reconstruction', recon_loss.item(), global_step)\n",
        "                writer.add_scalar('Loss/VAE_KLD', kld_loss.item(), global_step)\n",
        "                writer.add_scalar('Loss/Diffusion', diffusion_loss.item(), global_step)\n",
        "\n",
        "                # Visualize reconstructions periodically\n",
        "                if global_step % 100 == 0:\n",
        "                    with torch.no_grad():\n",
        "                        # Get original and reconstructed images\n",
        "                        orig_imgs = ego_images[:4].detach().cpu()\n",
        "                        recon_imgs = recon_images[:4].detach().cpu()\n",
        "\n",
        "                        # Create grid with original and reconstructed\n",
        "                        comparison = torch.cat([orig_imgs, recon_imgs], dim=0)\n",
        "\n",
        "                        # Convert from [-1,1] to [0,1] for visualization\n",
        "                        comparison = (comparison + 1) / 2\n",
        "\n",
        "                        # Add to tensorboard\n",
        "                        writer.add_images('Images/Reconstruction', comparison, global_step)\n",
        "\n",
        "                        # If we've trained enough, generate samples from the diffusion model\n",
        "                        if epoch > 5:  # Wait until diffusion model has learned something\n",
        "                            try:\n",
        "                                # Sample latent vectors from the diffusion model\n",
        "                                sampled_z = diffusion.sample(\n",
        "                                    shape=(4, config.latent_dim),\n",
        "                                    device=config.device,\n",
        "                                    steps=50  # Use fewer steps for visualization\n",
        "                                )\n",
        "\n",
        "                                # Decode the sampled latent vectors\n",
        "                                sampled_images = vae.decode(sampled_z)\n",
        "\n",
        "                                # Convert from [-1,1] to [0,1] for visualization\n",
        "                                sampled_images = (sampled_images + 1) / 2\n",
        "\n",
        "                                # Add to tensorboard\n",
        "                                writer.add_images('Images/Generated', sampled_images, global_step)\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error generating samples: {e}\")\n",
        "\n",
        "                global_step += 1\n",
        "            else:\n",
        "                print(\"Warning: Batch does not contain 'vehicle_images' key\")\n",
        "\n",
        "        # Update learning rate schedulers\n",
        "        vae_scheduler.step()\n",
        "        diffusion_scheduler.step()\n",
        "\n",
        "        # Calculate average losses for the epoch\n",
        "        avg_vae_loss = epoch_vae_loss / len(dataloader)\n",
        "        avg_recon_loss = epoch_recon_loss / len(dataloader)\n",
        "        avg_kld_loss = epoch_kld_loss / len(dataloader)\n",
        "        avg_diffusion_loss = epoch_diffusion_loss / len(dataloader)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nEpoch {epoch+1}/{config.num_epochs} completed in {epoch_time:.2f}s\")\n",
        "        print(f\"VAE Loss: {avg_vae_loss:.4f} (Recon: {avg_recon_loss:.4f}, KLD: {avg_kld_loss:.4f})\")\n",
        "        print(f\"Diffusion Loss: {avg_diffusion_loss:.4f}\")\n",
        "\n",
        "        # Save model checkpoint if it's the best so far\n",
        "        if avg_vae_loss + avg_diffusion_loss < best_loss:\n",
        "            best_loss = avg_vae_loss + avg_diffusion_loss\n",
        "\n",
        "            # Save best model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'vae_state_dict': vae.state_dict(),\n",
        "                'diffusion_state_dict': diffusion.state_dict(),\n",
        "                'vae_optimizer': vae_optimizer.state_dict(),\n",
        "                'diffusion_optimizer': diffusion_optimizer.state_dict(),\n",
        "                'loss': best_loss,\n",
        "            }, os.path.join(config.output_dir, 'best_model.pt'))\n",
        "\n",
        "            print(f\"âœ… Saved best model checkpoint with loss: {best_loss:.4f}\")\n",
        "\n",
        "        # Save regular checkpoint at intervals\n",
        "        if (epoch + 1) % config.save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'vae_state_dict': vae.state_dict(),\n",
        "                'diffusion_state_dict': diffusion.state_dict(),\n",
        "                'vae_optimizer': vae_optimizer.state_dict(),\n",
        "                'diffusion_optimizer': diffusion_optimizer.state_dict(),\n",
        "            }, os.path.join(config.output_dir, f'checkpoint_epoch_{epoch+1}.pt'))\n",
        "\n",
        "            print(f\"ðŸ“ Saved checkpoint at epoch {epoch+1}\")\n",
        "\n",
        "    # Save final model\n",
        "    torch.save({\n",
        "        'vae_state_dict': vae.state_dict(),\n",
        "        'diffusion_state_dict': diffusion.state_dict(),\n",
        "    }, os.path.join(config.output_dir, 'final_model.pt'))\n",
        "\n",
        "    print(f\"ðŸŽ‰ Training completed! Final model saved to {config.output_dir}\")\n",
        "    writer.close()\n",
        "\n",
        "    return vae, diffusion\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Make sure Google Drive is mounted\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"Google Drive mounted successfully\")\n",
        "    except:\n",
        "        print(\"Not running in Colab or Drive already mounted\")\n",
        "\n",
        "    # Import necessary modules\n",
        "    import torch\n",
        "    from torchvision import transforms\n",
        "\n",
        "    # Start training\n",
        "    vae, diffusion = train_adversarial_defense_system()\n",
        "\n",
        "    print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH5wkSuEH_PQ",
        "outputId": "d3351323-8cb4-447c-edd8-36a02425a0b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully\n",
            "Using device: cuda\n",
            "Found 74 images in /content/drive/MyDrive/CVProject/\n",
            "Dataset created with 74 images, 5 simulated vehicles\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:22<00:09,  3.11s/it, VAE Loss=129413.2812, Diff Loss=1.0225]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:34<00:00,  3.79s/it, VAE Loss=81356.1562, Diff Loss=1.0048]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50 completed in 34.15s\n",
            "VAE Loss: 134616.2083 (Recon: 134610.2127, KLD: 1199.1952)\n",
            "Diffusion Loss: 1.0119\n",
            "âœ… Saved best model checkpoint with loss: 134617.2202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.77it/s, VAE Loss=87375.1641, Diff Loss=1.4291]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/50 completed in 2.39s\n",
            "VAE Loss: 124484.3351 (Recon: 89815.0477, KLD: 6933858.1437)\n",
            "Diffusion Loss: 2.5176\n",
            "âœ… Saved best model checkpoint with loss: 124486.8526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:01<00:01,  3.56it/s, VAE Loss=86227.5938, Diff Loss=1.0066]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.79it/s, VAE Loss=76155.3125, Diff Loss=1.6579]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/50 completed in 1.88s\n",
            "VAE Loss: 80954.0495 (Recon: 76878.1137, KLD: 815187.3107)\n",
            "Diffusion Loss: 1.6939\n",
            "âœ… Saved best model checkpoint with loss: 80955.7433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.01it/s, VAE Loss=102391.7656, Diff Loss=1.0406]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.51it/s, VAE Loss=54314.1523, Diff Loss=0.8769]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/50 completed in 2.00s\n",
            "VAE Loss: 74295.6541 (Recon: 72647.6458, KLD: 329601.3977)\n",
            "Diffusion Loss: 1.2519\n",
            "âœ… Saved best model checkpoint with loss: 74296.9060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.91it/s, VAE Loss=65599.2734, Diff Loss=0.9052]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/50 completed in 3.11s\n",
            "VAE Loss: 72123.1042 (Recon: 71971.3902, KLD: 30342.8727)\n",
            "Diffusion Loss: 0.9610\n",
            "âœ… Saved best model checkpoint with loss: 72124.0652\n",
            "ðŸ“ Saved checkpoint at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  4.44it/s, VAE Loss=63397.5430, Diff Loss=0.9913]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.77it/s, VAE Loss=59192.3047, Diff Loss=1.1357]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/50 completed in 1.89s\n",
            "VAE Loss: 67050.6905 (Recon: 67005.1315, KLD: 9111.8090)\n",
            "Diffusion Loss: 1.0384\n",
            "âœ… Saved best model checkpoint with loss: 67051.7289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 7/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.14it/s, VAE Loss=64807.4062, Diff Loss=1.0410]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/50 completed in 1.75s\n",
            "VAE Loss: 60750.4826 (Recon: 60730.8941, KLD: 3917.7077)\n",
            "Diffusion Loss: 1.0053\n",
            "âœ… Saved best model checkpoint with loss: 60751.4879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.81it/s, VAE Loss=50694.7383, Diff Loss=0.9522]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/50 completed in 2.37s\n",
            "VAE Loss: 57096.1749 (Recon: 57077.3594, KLD: 3763.2348)\n",
            "Diffusion Loss: 0.9565\n",
            "âœ… Saved best model checkpoint with loss: 57097.1314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:01,  2.97it/s, VAE Loss=51232.7070, Diff Loss=0.9478]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 9/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:01,  2.97it/s, VAE Loss=44590.8672, Diff Loss=0.9954]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.54it/s, VAE Loss=37473.5898, Diff Loss=1.1154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/50 completed in 2.55s\n",
            "VAE Loss: 47116.6267 (Recon: 47090.2530, KLD: 5274.6600)\n",
            "Diffusion Loss: 1.0132\n",
            "âœ… Saved best model checkpoint with loss: 47117.6400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:01,  3.00it/s, VAE Loss=48951.0625, Diff Loss=0.9680]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.78it/s, VAE Loss=54432.8047, Diff Loss=1.0368]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/50 completed in 2.38s\n",
            "VAE Loss: 49220.4371 (Recon: 49205.1853, KLD: 3050.2463)\n",
            "Diffusion Loss: 1.0268\n",
            "ðŸ“ Saved checkpoint at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  4.90it/s, VAE Loss=55151.3281, Diff Loss=0.8834]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.43it/s, VAE Loss=47757.9023, Diff Loss=1.0196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11/50 completed in 2.04s\n",
            "VAE Loss: 52242.5556 (Recon: 52193.1823, KLD: 9874.6398)\n",
            "Diffusion Loss: 1.0115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.25it/s, VAE Loss=54714.7422, Diff Loss=0.9970]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.34it/s, VAE Loss=39795.5742, Diff Loss=1.0071]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12/50 completed in 2.08s\n",
            "VAE Loss: 45674.3342 (Recon: 45649.5009, KLD: 4966.6774)\n",
            "Diffusion Loss: 0.9977\n",
            "âœ… Saved best model checkpoint with loss: 45675.3319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 13/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.20it/s, VAE Loss=38010.0664, Diff Loss=0.9753]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13/50 completed in 1.73s\n",
            "VAE Loss: 42380.7947 (Recon: 42352.1576, KLD: 5727.5265)\n",
            "Diffusion Loss: 0.9950\n",
            "âœ… Saved best model checkpoint with loss: 42381.7898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 14/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.74it/s, VAE Loss=38925.6133, Diff Loss=0.9121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14/50 completed in 1.90s\n",
            "VAE Loss: 46674.3581 (Recon: 46656.5990, KLD: 3551.7958)\n",
            "Diffusion Loss: 0.9759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:01<00:02,  2.61it/s, VAE Loss=44102.8008, Diff Loss=1.0705]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.05it/s, VAE Loss=41823.2578, Diff Loss=1.0156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15/50 completed in 2.95s\n",
            "VAE Loss: 42667.1163 (Recon: 42646.8867, KLD: 4045.9120)\n",
            "Diffusion Loss: 1.0186\n",
            "ðŸ“ Saved checkpoint at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:01<00:02,  2.25it/s, VAE Loss=37855.6367, Diff Loss=0.9564]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.97it/s, VAE Loss=43036.7031, Diff Loss=1.0044]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16/50 completed in 3.03s\n",
            "VAE Loss: 41049.7921 (Recon: 41029.3424, KLD: 4089.9898)\n",
            "Diffusion Loss: 1.0432\n",
            "âœ… Saved best model checkpoint with loss: 41050.8353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:01<00:01,  3.14it/s, VAE Loss=43734.8086, Diff Loss=0.9467]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.31it/s, VAE Loss=42028.2969, Diff Loss=1.0432]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17/50 completed in 2.09s\n",
            "VAE Loss: 45254.2361 (Recon: 45236.2964, KLD: 3587.8851)\n",
            "Diffusion Loss: 1.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50:  11%|â–ˆ         | 1/9 [00:00<00:03,  2.18it/s, VAE Loss=38763.3906, Diff Loss=1.0335]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.20it/s, VAE Loss=39511.1875, Diff Loss=1.0922]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18/50 completed in 1.74s\n",
            "VAE Loss: 38385.4833 (Recon: 38371.2135, KLD: 2853.9362)\n",
            "Diffusion Loss: 1.0191\n",
            "âœ… Saved best model checkpoint with loss: 38386.5024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 19/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.72it/s, VAE Loss=34211.2578, Diff Loss=1.0234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19/50 completed in 1.91s\n",
            "VAE Loss: 43339.6267 (Recon: 43324.2856, KLD: 3068.1792)\n",
            "Diffusion Loss: 1.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50:  11%|â–ˆ         | 1/9 [00:00<00:03,  2.12it/s, VAE Loss=33090.9961, Diff Loss=0.9460]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.74it/s, VAE Loss=26580.4727, Diff Loss=0.9927]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20/50 completed in 1.90s\n",
            "VAE Loss: 33979.5143 (Recon: 33963.8880, KLD: 3125.2786)\n",
            "Diffusion Loss: 0.9762\n",
            "âœ… Saved best model checkpoint with loss: 33980.4906\n",
            "ðŸ“ Saved checkpoint at epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 21/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.59it/s, VAE Loss=40031.4922, Diff Loss=1.0373]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21/50 completed in 1.99s\n",
            "VAE Loss: 36420.5074 (Recon: 36406.0315, KLD: 2895.3071)\n",
            "Diffusion Loss: 0.9815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50:  11%|â–ˆ         | 1/9 [00:00<00:03,  2.00it/s, VAE Loss=36463.5430, Diff Loss=0.9445]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.73it/s, VAE Loss=37947.6680, Diff Loss=1.0478]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22/50 completed in 1.91s\n",
            "VAE Loss: 36704.2014 (Recon: 36690.2604, KLD: 2788.1391)\n",
            "Diffusion Loss: 0.9818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  5.01it/s, VAE Loss=33588.3320, Diff Loss=0.9873]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.58it/s, VAE Loss=43528.7148, Diff Loss=0.9229]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23/50 completed in 1.97s\n",
            "VAE Loss: 39290.0519 (Recon: 39276.6298, KLD: 2684.4361)\n",
            "Diffusion Loss: 1.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50:  11%|â–ˆ         | 1/9 [00:00<00:04,  1.92it/s, VAE Loss=32520.1816, Diff Loss=1.0626]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.82it/s, VAE Loss=31243.7383, Diff Loss=0.9910]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24/50 completed in 1.87s\n",
            "VAE Loss: 33664.2687 (Recon: 33649.8989, KLD: 2873.9100)\n",
            "Diffusion Loss: 1.0236\n",
            "âœ… Saved best model checkpoint with loss: 33665.2923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 25/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.80it/s, VAE Loss=27654.9902, Diff Loss=1.0553]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25/50 completed in 1.88s\n",
            "VAE Loss: 33533.3494 (Recon: 33519.9967, KLD: 2670.5895)\n",
            "Diffusion Loss: 1.0214\n",
            "âœ… Saved best model checkpoint with loss: 33534.3708\n",
            "ðŸ“ Saved checkpoint at epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:01<00:01,  3.18it/s, VAE Loss=23521.9863, Diff Loss=1.0863]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.68it/s, VAE Loss=35561.3828, Diff Loss=0.9466]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 26/50 completed in 1.92s\n",
            "VAE Loss: 31766.7216 (Recon: 31753.7754, KLD: 2589.3197)\n",
            "Diffusion Loss: 0.9872\n",
            "âœ… Saved best model checkpoint with loss: 31767.7088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  5.19it/s, VAE Loss=30020.7949, Diff Loss=1.0516]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.03it/s, VAE Loss=33451.0312, Diff Loss=0.9785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 27/50 completed in 1.79s\n",
            "VAE Loss: 32963.8190 (Recon: 32951.1701, KLD: 2529.7776)\n",
            "Diffusion Loss: 0.9786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50:  11%|â–ˆ         | 1/9 [00:00<00:03,  2.06it/s, VAE Loss=22627.8164, Diff Loss=0.9730]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.16it/s, VAE Loss=28172.2246, Diff Loss=1.0205]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 28/50 completed in 1.75s\n",
            "VAE Loss: 30627.3438 (Recon: 30614.6398, KLD: 2540.7520)\n",
            "Diffusion Loss: 0.9985\n",
            "âœ… Saved best model checkpoint with loss: 30628.3423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 29/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.31it/s, VAE Loss=21077.4668, Diff Loss=1.1388]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 29/50 completed in 2.09s\n",
            "VAE Loss: 32241.5022 (Recon: 32229.2166, KLD: 2457.1306)\n",
            "Diffusion Loss: 0.9687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:02<00:00,  3.02it/s, VAE Loss=28255.4316, Diff Loss=1.1634]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.79it/s, VAE Loss=27900.3457, Diff Loss=1.0768]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30/50 completed in 3.23s\n",
            "VAE Loss: 31449.4861 (Recon: 31437.6398, KLD: 2369.2810)\n",
            "Diffusion Loss: 1.0447\n",
            "ðŸ“ Saved checkpoint at epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  3.55it/s, VAE Loss=26279.1465, Diff Loss=0.9555]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.78it/s, VAE Loss=32239.9102, Diff Loss=1.0444]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 31/50 completed in 1.90s\n",
            "VAE Loss: 29749.0406 (Recon: 29736.4757, KLD: 2512.9367)\n",
            "Diffusion Loss: 0.9945\n",
            "âœ… Saved best model checkpoint with loss: 29750.0351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 32/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.12it/s, VAE Loss=28549.0820, Diff Loss=0.9447]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 32/50 completed in 1.77s\n",
            "VAE Loss: 28303.3843 (Recon: 28291.0345, KLD: 2470.0353)\n",
            "Diffusion Loss: 1.0105\n",
            "âœ… Saved best model checkpoint with loss: 28304.3948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:02<00:00,  3.26it/s, VAE Loss=24438.9434, Diff Loss=0.8950]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.33it/s, VAE Loss=45548.9492, Diff Loss=1.0027]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 33/50 completed in 2.71s\n",
            "VAE Loss: 31214.3743 (Recon: 31202.4004, KLD: 2394.8228)\n",
            "Diffusion Loss: 0.9525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:01<00:00,  3.84it/s, VAE Loss=32041.9297, Diff Loss=0.9248]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.68it/s, VAE Loss=24967.4707, Diff Loss=1.0341]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 34/50 completed in 2.45s\n",
            "VAE Loss: 29755.6233 (Recon: 29742.7515, KLD: 2574.3823)\n",
            "Diffusion Loss: 0.9904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.46it/s, VAE Loss=27200.5195, Diff Loss=0.9377]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 35/50 completed in 2.02s\n",
            "VAE Loss: 30649.3774 (Recon: 30637.0228, KLD: 2470.8633)\n",
            "Diffusion Loss: 0.9624\n",
            "ðŸ“ Saved checkpoint at epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.98it/s, VAE Loss=25975.0566, Diff Loss=0.8584]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.13it/s, VAE Loss=27932.7188, Diff Loss=0.9154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 36/50 completed in 1.76s\n",
            "VAE Loss: 28313.2604 (Recon: 28300.5831, KLD: 2535.4395)\n",
            "Diffusion Loss: 0.9623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.20it/s, VAE Loss=25031.9844, Diff Loss=1.0119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 37/50 completed in 2.82s\n",
            "VAE Loss: 29850.6283 (Recon: 29838.9659, KLD: 2332.4395)\n",
            "Diffusion Loss: 0.9782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50:  11%|â–ˆ         | 1/9 [00:00<00:05,  1.39it/s, VAE Loss=36677.8242, Diff Loss=1.0407]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.92it/s, VAE Loss=27382.2695, Diff Loss=1.0176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 38/50 completed in 2.30s\n",
            "VAE Loss: 28696.3132 (Recon: 28683.6328, KLD: 2536.1191)\n",
            "Diffusion Loss: 1.0073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 39/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.23it/s, VAE Loss=29918.2070, Diff Loss=0.8744]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 39/50 completed in 1.72s\n",
            "VAE Loss: 26163.4924 (Recon: 26151.4108, KLD: 2416.3228)\n",
            "Diffusion Loss: 0.9960\n",
            "âœ… Saved best model checkpoint with loss: 26164.4884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50:  11%|â–ˆ         | 1/9 [00:00<00:05,  1.53it/s, VAE Loss=26160.8223, Diff Loss=1.0865]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.39it/s, VAE Loss=35526.8438, Diff Loss=0.8938]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 40/50 completed in 2.05s\n",
            "VAE Loss: 25562.8793 (Recon: 25550.9097, KLD: 2393.8676)\n",
            "Diffusion Loss: 0.9987\n",
            "âœ… Saved best model checkpoint with loss: 25563.8780\n",
            "ðŸ“ Saved checkpoint at epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:01,  2.89it/s, VAE Loss=23023.7402, Diff Loss=1.0078]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.85it/s, VAE Loss=24424.1836, Diff Loss=0.9247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 41/50 completed in 3.18s\n",
            "VAE Loss: 25484.8045 (Recon: 25473.0768, KLD: 2345.5120)\n",
            "Diffusion Loss: 1.0019\n",
            "âœ… Saved best model checkpoint with loss: 25485.8063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  5.24it/s, VAE Loss=17350.9805, Diff Loss=1.1463]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.14it/s, VAE Loss=24106.5430, Diff Loss=0.8991]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 42/50 completed in 1.75s\n",
            "VAE Loss: 23819.3153 (Recon: 23807.4288, KLD: 2377.3732)\n",
            "Diffusion Loss: 0.9819\n",
            "âœ… Saved best model checkpoint with loss: 23820.2973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50:  11%|â–ˆ         | 1/9 [00:00<00:03,  2.01it/s, VAE Loss=30851.2617, Diff Loss=1.0345]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.77it/s, VAE Loss=29005.0371, Diff Loss=1.0898]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 43/50 completed in 1.89s\n",
            "VAE Loss: 28287.1645 (Recon: 28274.8895, KLD: 2454.9372)\n",
            "Diffusion Loss: 1.0546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:00<00:01,  4.16it/s, VAE Loss=28303.6016, Diff Loss=0.9207]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.21it/s, VAE Loss=33444.3242, Diff Loss=0.8517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 44/50 completed in 1.73s\n",
            "VAE Loss: 24658.5460 (Recon: 24646.3520, KLD: 2438.8491)\n",
            "Diffusion Loss: 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:01<00:00,  5.05it/s, VAE Loss=22125.0586, Diff Loss=1.0978]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.39it/s, VAE Loss=32942.6953, Diff Loss=0.9454]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 45/50 completed in 2.05s\n",
            "VAE Loss: 25934.6651 (Recon: 25922.8813, KLD: 2356.7317)\n",
            "Diffusion Loss: 0.9908\n",
            "ðŸ“ Saved checkpoint at epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:01<00:00,  4.68it/s, VAE Loss=31848.8730, Diff Loss=1.0857]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.25it/s, VAE Loss=35030.5586, Diff Loss=1.0371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 46/50 completed in 2.12s\n",
            "VAE Loss: 29261.3312 (Recon: 29249.2945, KLD: 2407.3367)\n",
            "Diffusion Loss: 0.9846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.45it/s, VAE Loss=21160.9414, Diff Loss=0.9638]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.63it/s, VAE Loss=32486.1367, Diff Loss=0.9316]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 47/50 completed in 1.95s\n",
            "VAE Loss: 28554.6610 (Recon: 28542.8503, KLD: 2362.1025)\n",
            "Diffusion Loss: 0.9796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 48/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.95it/s, VAE Loss=26911.1777, Diff Loss=0.9211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 48/50 completed in 1.82s\n",
            "VAE Loss: 28461.9468 (Recon: 28450.5849, KLD: 2272.3033)\n",
            "Diffusion Loss: 0.9784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:01<00:00,  4.70it/s, VAE Loss=20451.7734, Diff Loss=0.9778]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.62it/s, VAE Loss=21816.9707, Diff Loss=1.0976]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 49/50 completed in 1.95s\n",
            "VAE Loss: 26696.3724 (Recon: 26684.4464, KLD: 2385.1587)\n",
            "Diffusion Loss: 1.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 50/50:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.86it/s, VAE Loss=25870.7812, Diff Loss=0.9840]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 50/50 completed in 2.34s\n",
            "VAE Loss: 23510.8483 (Recon: 23498.8145, KLD: 2406.7449)\n",
            "Diffusion Loss: 0.9882\n",
            "âœ… Saved best model checkpoint with loss: 23511.8365\n",
            "ðŸ“ Saved checkpoint at epoch 50\n",
            "ðŸŽ‰ Training completed! Final model saved to /content/drive/MyDrive/CVProject/output/\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class ThreatDetector(nn.Module):\n",
        "    def __init__(self, latent_dim=64, num_vehicles=5):\n",
        "        super(ThreatDetector, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_vehicles = num_vehicles\n",
        "\n",
        "        # Feature extractor\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        # Uncertainty estimator (aleatoric uncertainty)\n",
        "        self.uncertainty_estimator = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(32, 2)  # Mean and log variance for uncertainty\n",
        "        )\n",
        "\n",
        "        # Trust score predictor\n",
        "        self.trust_predictor = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()  # Output between 0 and 1 (trust score)\n",
        "        )\n",
        "\n",
        "        # Consensus module for multi-vehicle analysis\n",
        "        self.consensus_module = nn.Sequential(\n",
        "            nn.Linear(num_vehicles, 32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(32, num_vehicles),\n",
        "            nn.Softmax(dim=1)  # Weights for each vehicle\n",
        "        )\n",
        "\n",
        "    def forward(self, latent_vectors_list):\n",
        "        \"\"\"\n",
        "        Process latent vectors from multiple vehicles\n",
        "\n",
        "        Args:\n",
        "            latent_vectors_list: List of latent vectors from different vehicles\n",
        "                          Shape: List of [batch_size, latent_dim] tensors\n",
        "        \"\"\"\n",
        "        batch_size = latent_vectors_list[0].shape[0]\n",
        "\n",
        "        # Process latent vectors from each vehicle\n",
        "        features_list = []\n",
        "        uncertainty_list = []\n",
        "        trust_scores = []\n",
        "\n",
        "        for vehicle_latent in latent_vectors_list:\n",
        "            # Extract features\n",
        "            features = self.feature_extractor(vehicle_latent)\n",
        "            features_list.append(features)\n",
        "\n",
        "            # Estimate uncertainty\n",
        "            uncertainty_params = self.uncertainty_estimator(features)\n",
        "            uncertainty_mean, uncertainty_log_var = uncertainty_params.chunk(2, dim=1)\n",
        "            uncertainty_list.append((uncertainty_mean, uncertainty_log_var))\n",
        "\n",
        "            # Calculate trust score\n",
        "            trust_score = self.trust_predictor(features)\n",
        "            trust_scores.append(trust_score)\n",
        "\n",
        "        # Stack trust scores for consensus [batch_size, num_vehicles]\n",
        "        trust_scores_stacked = torch.cat(trust_scores, dim=1)\n",
        "\n",
        "        # Apply consensus to get refined vehicle weights\n",
        "        vehicle_weights = self.consensus_module(trust_scores_stacked)\n",
        "\n",
        "        # Identify potential adversaries (vehicles with low trust)\n",
        "        adversarial_threshold = 0.5\n",
        "        potential_adversaries = (vehicle_weights < adversarial_threshold)\n",
        "\n",
        "        # Apply ROBOSAC-inspired consensus approach\n",
        "        selected_vehicles = torch.zeros_like(potential_adversaries).float()\n",
        "        max_iterations = min(10, self.num_vehicles)\n",
        "\n",
        "        # For each batch item\n",
        "        for b in range(batch_size):\n",
        "            # Get trust scores and adversarial flags for this batch item\n",
        "            batch_trust = trust_scores_stacked[b]\n",
        "            batch_adversarial = potential_adversaries[b]\n",
        "\n",
        "            best_consensus_score = -1\n",
        "            best_selection = None\n",
        "\n",
        "            # Try different random subsets to find best consensus\n",
        "            for _ in range(max_iterations):\n",
        "                # Generate random selection (with higher probability for non-adversarial vehicles)\n",
        "                selection_probs = (~batch_adversarial).float() * 0.8 + 0.2\n",
        "                selection = torch.bernoulli(selection_probs).bool()\n",
        "\n",
        "                # Ensure at least 2 vehicles are selected\n",
        "                if selection.sum() < 2:\n",
        "                    # Select top-2 by trust score\n",
        "                    _, top_indices = torch.topk(batch_trust, k=2)\n",
        "                    selection = torch.zeros_like(selection)\n",
        "                    selection[top_indices] = True\n",
        "\n",
        "                # Calculate consensus score (average trust among selected)\n",
        "                selected_trust = batch_trust[selection]\n",
        "                consensus_score = selected_trust.mean().item()\n",
        "\n",
        "                # Update best selection if better consensus found\n",
        "                if consensus_score > best_consensus_score:\n",
        "                    best_consensus_score = consensus_score\n",
        "                    best_selection = selection\n",
        "\n",
        "            # Use best selection for this batch item\n",
        "            selected_vehicles[b] = best_selection.float()\n",
        "\n",
        "        return {\n",
        "            'trust_scores': trust_scores_stacked,\n",
        "            'vehicle_weights': vehicle_weights,\n",
        "            'selected_vehicles': selected_vehicles,\n",
        "            'uncertainty_estimates': uncertainty_list,\n",
        "            'potential_adversaries': potential_adversaries\n",
        "        }\n",
        "\n",
        "\n",
        "class AdversarialDefenseSystem(nn.Module):\n",
        "    def __init__(self, vae, diffusion, latent_dim=64, num_vehicles=5):\n",
        "        super(AdversarialDefenseSystem, self).__init__()\n",
        "\n",
        "        # Feature compression using VAE\n",
        "        self.vae = vae\n",
        "\n",
        "        # Diffusion model for uncertainty modeling\n",
        "        self.diffusion = diffusion\n",
        "\n",
        "        # Threat detection\n",
        "        self.threat_detector = ThreatDetector(\n",
        "            latent_dim=latent_dim,\n",
        "            num_vehicles=num_vehicles\n",
        "        )\n",
        "\n",
        "        # Feature fusion for final output\n",
        "        self.feature_fusion = nn.Sequential(\n",
        "            nn.Linear(latent_dim, latent_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(latent_dim, latent_dim)\n",
        "        )\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_vehicles = num_vehicles\n",
        "\n",
        "    def forward(self, vehicle_images, inference_mode=True):\n",
        "        \"\"\"\n",
        "        Process images from multiple vehicles\n",
        "\n",
        "        Args:\n",
        "            vehicle_images: List of images from different vehicles\n",
        "                           [num_vehicles, batch_size, C, H, W]\n",
        "            inference_mode: If True, don't add diffusion noise (for inference)\n",
        "        \"\"\"\n",
        "        batch_size = vehicle_images[0].shape[0]\n",
        "\n",
        "        # Compress features using VAE for each vehicle\n",
        "        latent_vectors = []\n",
        "        reconstructions = []\n",
        "\n",
        "        with torch.no_grad() if inference_mode else torch.enable_grad():\n",
        "            for vehicle_idx, images in enumerate(vehicle_images):\n",
        "                # Encode images to get latent vectors\n",
        "                recon, mu, log_var, z_sparse = self.vae(images)\n",
        "\n",
        "                # Add to lists\n",
        "                latent_vectors.append(z_sparse)\n",
        "                reconstructions.append(recon)\n",
        "\n",
        "        # Detect threats using latent vectors\n",
        "        threat_results = self.threat_detector(latent_vectors)\n",
        "\n",
        "        # Apply weighted fusion based on threat detection\n",
        "        selected_vehicles = threat_results['selected_vehicles']\n",
        "        fused_features = torch.zeros(batch_size, self.latent_dim).to(vehicle_images[0].device)\n",
        "\n",
        "        # For each item in batch\n",
        "        for b in range(batch_size):\n",
        "            # Get selected vehicles for this batch item\n",
        "            selected = selected_vehicles[b].bool()\n",
        "\n",
        "            # If no vehicle is selected (extreme case), use the ego vehicle\n",
        "            if not selected.any():\n",
        "                selected[0] = True\n",
        "\n",
        "            # Get latent vectors from selected vehicles\n",
        "            selected_latents = []\n",
        "            for v in range(self.num_vehicles):\n",
        "                if selected[v]:\n",
        "                    selected_latents.append(latent_vectors[v][b:b+1])\n",
        "\n",
        "            # Average selected latent vectors\n",
        "            if selected_latents:\n",
        "                selected_avg = torch.cat(selected_latents, dim=0).mean(dim=0, keepdim=True)\n",
        "                fused_features[b:b+1] = selected_avg\n",
        "\n",
        "        # Apply feature fusion network\n",
        "        fused_features = self.feature_fusion(fused_features)\n",
        "\n",
        "        # Decode fused features\n",
        "        with torch.no_grad() if inference_mode else torch.enable_grad():\n",
        "            fused_reconstruction = self.vae.decode(fused_features)\n",
        "\n",
        "        return {\n",
        "            'fused_reconstruction': fused_reconstruction,\n",
        "            'vehicle_reconstructions': reconstructions,\n",
        "            'threat_results': threat_results,\n",
        "            'latent_vectors': latent_vectors,\n",
        "            'fused_features': fused_features\n",
        "        }\n",
        "\n",
        "    def detect_adversarial(self, vehicle_images, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Simple function to detect which vehicles are adversarial\n",
        "\n",
        "        Args:\n",
        "            vehicle_images: List of images from different vehicles\n",
        "            threshold: Trust score threshold below which a vehicle is considered adversarial\n",
        "\n",
        "        Returns:\n",
        "            List of booleans indicating which vehicles are adversarial\n",
        "        \"\"\"\n",
        "        # Forward pass\n",
        "        results = self.forward(vehicle_images, inference_mode=True)\n",
        "\n",
        "        # Get trust scores\n",
        "        trust_scores = results['threat_results']['trust_scores']\n",
        "\n",
        "        # Detect adversarial vehicles (low trust score)\n",
        "        adversarial_vehicles = (trust_scores < threshold).cpu().numpy()\n",
        "\n",
        "        return adversarial_vehicles"
      ],
      "metadata": {
        "id": "xU1FW8I2IEFw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "from torchvision import transforms\n",
        "\n",
        "# Add any additional imports needed from your modules\n",
        "# from models.feature_compression import FeatureCompressionVAE\n",
        "# from models.diffusion import DiffusionModel\n",
        "# from models.adversarial_defense import AdversarialDefenseSystem\n",
        "# from data.dataset import VehicularPerceptionDataset\n",
        "\n",
        "\n",
        "def apply_random_occlusion(images, occlusion_size=0.3):\n",
        "    \"\"\"Apply random occlusion to images\"\"\"\n",
        "    perturbed = images.clone()\n",
        "    batch_size, c, h, w = images.shape\n",
        "\n",
        "    # Calculate occlusion dimensions\n",
        "    occlude_height = int(h * occlusion_size)\n",
        "    occlude_width = int(w * occlusion_size)\n",
        "\n",
        "    # Apply occlusion to each image\n",
        "    for i in range(batch_size):\n",
        "        # Random position\n",
        "        x = torch.randint(0, w - occlude_width, (1,)).item()\n",
        "        y = torch.randint(0, h - occlude_height, (1,)).item()\n",
        "\n",
        "        # Apply occlusion\n",
        "        perturbed[i, :, y:y+occlude_height, x:x+occlude_width] = 0\n",
        "\n",
        "    return perturbed\n",
        "\n",
        "\n",
        "def generate_fgsm_attack(images, model, epsilon=0.1):\n",
        "    \"\"\"Generate adversarial examples using FGSM\"\"\"\n",
        "    # Create a copy that requires gradient\n",
        "    perturbed_images = images.clone().detach().requires_grad_(True)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs, mu, log_var, _ = model(perturbed_images)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.mse_loss(outputs, images)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Generate perturbation\n",
        "    perturbation = epsilon * perturbed_images.grad.sign()\n",
        "\n",
        "    # Add perturbation\n",
        "    perturbed_images = perturbed_images + perturbation\n",
        "\n",
        "    # Ensure valid range\n",
        "    perturbed_images = torch.clamp(perturbed_images, -1, 1)\n",
        "\n",
        "    return perturbed_images.detach()\n",
        "\n",
        "\n",
        "def visualize_results(results, config):\n",
        "    \"\"\"Visualize evaluation results\"\"\"\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Metrics to plot\n",
        "    metrics = ['accuracy', 'false_positive', 'false_negative', 'latency']\n",
        "    titles = ['Detection Accuracy', 'False Positive Rate', 'False Negative Rate', 'Processing Time (ms)']\n",
        "\n",
        "    # Get attack names\n",
        "    attack_names = list(results.keys())\n",
        "\n",
        "    # Plot each metric\n",
        "    for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
        "        plt.subplot(2, 2, i + 1)\n",
        "\n",
        "        # Get values\n",
        "        values = [results[attack][metric] for attack in attack_names]\n",
        "\n",
        "        # Create bar plot\n",
        "        plt.bar(attack_names, values)\n",
        "        plt.title(title)\n",
        "        plt.ylim(0, 1.0 if metric != 'latency' else max(values) * 1.2)\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        # Add value labels\n",
        "        for j, v in enumerate(values):\n",
        "            plt.text(j, v + 0.02, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    save_path = os.path.join(config.output_dir, 'evaluation_results.png')\n",
        "    plt.savefig(save_path)\n",
        "    print(f\"Results visualization saved to {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluate_defense_system(config):\n",
        "    \"\"\"\n",
        "    Evaluate the adversarial defense system\n",
        "    \"\"\"\n",
        "    # Create dataset\n",
        "    dataset = VehicularPerceptionDataset(\n",
        "        root_dir=config.data_dir,\n",
        "        transform=None,  # No augmentation for evaluation\n",
        "        is_training=False,\n",
        "        num_vehicles=config.num_vehicles,\n",
        "        adversarial_prob=0.0  # We'll add adversarial samples manually\n",
        "    )\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers\n",
        "    )\n",
        "\n",
        "    # Create models\n",
        "    vae = FeatureCompressionVAE(\n",
        "        input_channels=config.input_channels,\n",
        "        latent_dim=config.latent_dim\n",
        "    ).to(config.device)\n",
        "\n",
        "    diffusion = DiffusionModel(\n",
        "        feature_dim=config.latent_dim,\n",
        "        timesteps=config.diffusion_timesteps\n",
        "    ).to(config.device)\n",
        "\n",
        "    # Load model weights\n",
        "    checkpoint = torch.load(config.model_path, map_location=config.device)\n",
        "    vae.load_state_dict(checkpoint['vae_state_dict'])\n",
        "    diffusion.load_state_dict(checkpoint['diffusion_state_dict'])\n",
        "\n",
        "    # Set models to evaluation mode\n",
        "    vae.eval()\n",
        "    diffusion.eval()\n",
        "\n",
        "    # Create defense system\n",
        "    defense_system = AdversarialDefenseSystem(\n",
        "        vae=vae,\n",
        "        diffusion=diffusion,\n",
        "        latent_dim=config.latent_dim,\n",
        "        num_vehicles=config.num_vehicles\n",
        "    ).to(config.device)\n",
        "\n",
        "    # Metrics\n",
        "    detection_accuracy = 0.0\n",
        "    false_positive_rate = 0.0\n",
        "    false_negative_rate = 0.0\n",
        "    processing_times = []\n",
        "\n",
        "    # Run evaluation for different attack types\n",
        "    attack_types = {\n",
        "        'Random Noise': lambda x: x + torch.randn_like(x) * config.attack_magnitude,\n",
        "        'Targeted Shift': lambda x: x + config.attack_magnitude,\n",
        "        'Random Occlusion': lambda x: apply_random_occlusion(x),\n",
        "        'Adversarial Example': lambda x: generate_fgsm_attack(x, vae)\n",
        "    }\n",
        "\n",
        "    # Results for each attack type\n",
        "    results = {attack: {\n",
        "        'accuracy': 0.0,\n",
        "        'false_positive': 0.0,\n",
        "        'false_negative': 0.0,\n",
        "        'latency': 0.0\n",
        "    } for attack in attack_types}\n",
        "\n",
        "    # For each attack type\n",
        "    for attack_name, attack_function in attack_types.items():\n",
        "        print(f\"\\nEvaluating attack: {attack_name}\")\n",
        "\n",
        "        # Reset metrics\n",
        "        correct_detections = 0\n",
        "        false_positives = 0\n",
        "        false_negatives = 0\n",
        "        total_samples = 0\n",
        "        total_benign = 0\n",
        "        total_adversarial = 0\n",
        "\n",
        "        # Process time\n",
        "        total_time = 0.0\n",
        "\n",
        "        # Process all batches\n",
        "        for batch_idx, batch in enumerate(tqdm(dataloader, desc=f\"Evaluating {attack_name}\")):\n",
        "            # Get vehicle images\n",
        "            if 'vehicle_images' in batch:\n",
        "                vehicle_images = batch['vehicle_images']\n",
        "                batch_size = vehicle_images[0].shape[0]\n",
        "\n",
        "                # Create list for adversarial images - FIX: Initialize empty list first\n",
        "                adversarial_images = []\n",
        "\n",
        "                # Keep track of which vehicles are adversarial\n",
        "                is_adversarial = np.zeros((batch_size, config.num_vehicles), dtype=bool)\n",
        "\n",
        "                # Apply attack to selected vehicles\n",
        "                for v in range(config.num_vehicles):\n",
        "                    if v in config.adversarial_vehicles:\n",
        "                        # Apply attack - move to device first\n",
        "                        original_img = vehicle_images[v].to(config.device)\n",
        "                        perturbed = attack_function(original_img)\n",
        "                        adversarial_images.append(perturbed)\n",
        "\n",
        "                        # Mark as adversarial\n",
        "                        is_adversarial[:, v] = True\n",
        "                    else:\n",
        "                        # Keep original - move to device\n",
        "                        adversarial_images.append(vehicle_images[v].to(config.device))\n",
        "\n",
        "                # Measure processing time\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Run detection\n",
        "                detected_adversarial = defense_system.detect_adversarial(\n",
        "                    adversarial_images,\n",
        "                    threshold=config.adversarial_threshold\n",
        "                )\n",
        "\n",
        "                # Measure time\n",
        "                end_time = time.time()\n",
        "                processing_time = (end_time - start_time) * 1000  # ms\n",
        "\n",
        "                # Update metrics\n",
        "                for b in range(batch_size):\n",
        "                    for v in range(config.num_vehicles):\n",
        "                        # True adversarial status\n",
        "                        true_adversarial = is_adversarial[b, v]\n",
        "\n",
        "                        # Predicted adversarial status\n",
        "                        pred_adversarial = detected_adversarial[b, v]\n",
        "\n",
        "                        # Update counters\n",
        "                        total_samples += 1\n",
        "\n",
        "                        if true_adversarial:\n",
        "                            total_adversarial += 1\n",
        "                            if pred_adversarial:\n",
        "                                correct_detections += 1\n",
        "                            else:\n",
        "                                false_negatives += 1\n",
        "                        else:\n",
        "                            total_benign += 1\n",
        "                            if pred_adversarial:\n",
        "                                false_positives += 1\n",
        "                            else:\n",
        "                                correct_detections += 1\n",
        "\n",
        "                # Update total time\n",
        "                total_time += processing_time\n",
        "\n",
        "            # Limit evaluation to a few batches for quick testing\n",
        "            if config.quick_eval and batch_idx >= 10:\n",
        "                break\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = correct_detections / total_samples if total_samples > 0 else 0\n",
        "        fp_rate = false_positives / total_benign if total_benign > 0 else 0\n",
        "        fn_rate = false_negatives / total_adversarial if total_adversarial > 0 else 0\n",
        "        avg_time = total_time / (batch_idx + 1)\n",
        "\n",
        "        # Store results\n",
        "        results[attack_name]['accuracy'] = accuracy\n",
        "        results[attack_name]['false_positive'] = fp_rate\n",
        "        results[attack_name]['false_negative'] = fn_rate\n",
        "        results[attack_name]['latency'] = avg_time\n",
        "\n",
        "        print(f\"Results for {attack_name}:\")\n",
        "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"  False Positive Rate: {fp_rate:.4f}\")\n",
        "        print(f\"  False Negative Rate: {fn_rate:.4f}\")\n",
        "        print(f\"  Average Processing Time: {avg_time:.2f} ms\")\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(results, config)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate_system(vae, diffusion, test_dir='/content/drive/MyDrive/CVProject/test/'):\n",
        "    \"\"\"\n",
        "    Evaluate the trained system on test data\n",
        "    \"\"\"\n",
        "    # Create configuration\n",
        "    class EvalConfig:\n",
        "        data_dir = test_dir\n",
        "        batch_size = 4\n",
        "        num_workers = 2\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        num_vehicles = 5\n",
        "        adversarial_vehicles = [1, 3]  # Which vehicles to make adversarial\n",
        "        adversarial_magnitude = 0.2\n",
        "        output_dir = '/content/drive/MyDrive/CVProject/output/evaluation/'\n",
        "\n",
        "    config = EvalConfig()\n",
        "    os.makedirs(config.output_dir, exist_ok=True)\n",
        "\n",
        "    # Create evaluation dataset\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    test_dataset = VehicularPerceptionDataset(\n",
        "        root_dir=config.data_dir,\n",
        "        transform=transform,\n",
        "        is_training=False,\n",
        "        num_vehicles=config.num_vehicles,\n",
        "        adversarial_prob=0.0  # No random adversarial - we'll do it manually\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers\n",
        "    )\n",
        "\n",
        "    # Create the full defense system\n",
        "    # from models.adversarial_defense import AdversarialDefenseSystem, ThreatDetector\n",
        "\n",
        "    # Move models to device\n",
        "    vae = vae.to(config.device)\n",
        "    diffusion = diffusion.to(config.device)\n",
        "\n",
        "    # Create the defense system\n",
        "    defense_system = AdversarialDefenseSystem(\n",
        "        vae=vae,\n",
        "        diffusion=diffusion,\n",
        "        latent_dim=vae.fc_mu.out_features,  # Get latent dim from VAE\n",
        "        num_vehicles=config.num_vehicles\n",
        "    ).to(config.device)\n",
        "\n",
        "    # Set models to evaluation mode\n",
        "    vae.eval()\n",
        "    diffusion.eval()\n",
        "    defense_system.eval()\n",
        "\n",
        "    # Metrics\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    true_negatives = 0\n",
        "    false_negatives = 0\n",
        "\n",
        "    # Process test data\n",
        "    for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Evaluating\")):\n",
        "        if 'vehicle_images' in batch:\n",
        "            # Get vehicle images\n",
        "            vehicle_images = batch['vehicle_images']\n",
        "            batch_size = vehicle_images[0].shape[0]\n",
        "\n",
        "            # Apply adversarial perturbations to selected vehicles\n",
        "            for v_idx in config.adversarial_vehicles:\n",
        "                if v_idx < len(vehicle_images):\n",
        "                    # Apply adversarial perturbation\n",
        "                    vehicle_images[v_idx] = defense_system._apply_adversarial_perturbation(\n",
        "                        vehicle_images[v_idx],\n",
        "                        magnitude=config.adversarial_magnitude\n",
        "                    )\n",
        "\n",
        "            # Move to device\n",
        "            vehicle_images = [img.to(config.device) for img in vehicle_images]\n",
        "\n",
        "            # Detect adversarial vehicles\n",
        "            with torch.no_grad():\n",
        "                results = defense_system.forward(vehicle_images, inference_mode=True)\n",
        "                threat_results = results['threat_results']\n",
        "                trust_scores = threat_results['trust_scores']\n",
        "\n",
        "                # Threshold for adversarial detection\n",
        "                is_adversarial = (trust_scores < 0.5).cpu().numpy()\n",
        "\n",
        "            # Calculate metrics\n",
        "            for v_idx in range(config.num_vehicles):\n",
        "                ground_truth = v_idx in config.adversarial_vehicles\n",
        "\n",
        "                for b in range(batch_size):\n",
        "                    predicted = is_adversarial[b, v_idx]\n",
        "\n",
        "                    if ground_truth and predicted:\n",
        "                        true_positives += 1\n",
        "                    elif ground_truth and not predicted:\n",
        "                        false_negatives += 1\n",
        "                    elif not ground_truth and predicted:\n",
        "                        false_positives += 1\n",
        "                    else:  # not ground_truth and not predicted\n",
        "                        true_negatives += 1\n",
        "\n",
        "            # Visualize results for the first batch\n",
        "            if batch_idx == 0:\n",
        "                fig, axes = plt.subplots(config.num_vehicles, 4, figsize=(16, 4*config.num_vehicles))\n",
        "\n",
        "                for v_idx in range(config.num_vehicles):\n",
        "                    for b in range(min(4, batch_size)):\n",
        "                        # Get the image\n",
        "                        img = vehicle_images[v_idx][b].cpu()\n",
        "\n",
        "                        # Convert from [-1,1] to [0,1] for display\n",
        "                        img = (img + 1) / 2\n",
        "\n",
        "                        # Plot the image\n",
        "                        ax = axes[v_idx, b]\n",
        "                        ax.imshow(img.permute(1, 2, 0))\n",
        "\n",
        "                        # Add title with adversarial status\n",
        "                        is_adv = v_idx in config.adversarial_vehicles\n",
        "                        predicted_adv = is_adversarial[b, v_idx]\n",
        "\n",
        "                        title = f\"V{v_idx}: \"\n",
        "                        title += \"Adv\" if is_adv else \"Clean\"\n",
        "                        title += \" (Detected)\" if predicted_adv else \" (Not Detected)\"\n",
        "\n",
        "                        # Color based on correct/incorrect prediction\n",
        "                        if (is_adv and predicted_adv) or (not is_adv and not predicted_adv):\n",
        "                            # Correct prediction\n",
        "                            ax.set_title(title, color='green')\n",
        "                        else:\n",
        "                            # Incorrect prediction\n",
        "                            ax.set_title(title, color='red')\n",
        "\n",
        "                        ax.axis('off')\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(config.output_dir, 'detection_results.png'))\n",
        "                plt.show()\n",
        "\n",
        "        # Limit to 10 batches for quick evaluation\n",
        "        if batch_idx >= 10:\n",
        "            break\n",
        "\n",
        "    # Calculate metrics\n",
        "    total = true_positives + true_negatives + false_positives + false_negatives\n",
        "    accuracy = (true_positives + true_negatives) / total if total > 0 else 0\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1_score:.4f}\")\n",
        "\n",
        "    # Create confusion matrix\n",
        "    confusion_matrix = [\n",
        "        [true_negatives, false_positives],\n",
        "        [false_negatives, true_positives]\n",
        "    ]\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(f\"TN: {true_negatives}, FP: {false_positives}\")\n",
        "    print(f\"FN: {false_negatives}, TP: {true_positives}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score,\n",
        "        'confusion_matrix': confusion_matrix\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    class Config:\n",
        "        # Paths\n",
        "        data_dir = '/content/drive/MyDrive/CVProject/'\n",
        "        output_dir = '/content/drive/MyDrive/CVProject/output/'\n",
        "        model_path = '/content/drive/MyDrive/CVProject/output/final_model.pt'\n",
        "\n",
        "        # Model parameters\n",
        "        input_channels = 3\n",
        "        latent_dim = 64\n",
        "        num_vehicles = 5\n",
        "        diffusion_timesteps = 100\n",
        "\n",
        "        # Evaluation parameters\n",
        "        batch_size = 8\n",
        "        num_workers = 2\n",
        "        adversarial_vehicles = [1, 3]  # Indices of vehicles to attack\n",
        "        adversarial_threshold = 0.5  # Trust score threshold\n",
        "        attack_magnitude = 0.2  # Magnitude of adversarial perturbation\n",
        "\n",
        "        # Quick evaluation flag (for testing)\n",
        "        quick_eval = True\n",
        "\n",
        "        # Device\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "    # You need to add your module imports here, before running evaluation\n",
        "    # from models.feature_compression import FeatureCompressionVAE\n",
        "    # from models.diffusion import DiffusionModel\n",
        "    # from models.adversarial_defense import AdversarialDefenseSystem, ThreatDetector\n",
        "    # from data.dataset import VehicularPerceptionDataset\n",
        "\n",
        "    # Run evaluation\n",
        "    results = evaluate_defense_system(Config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PUo2zS-CIH8F",
        "outputId": "127f83e3-2b8d-4e02-f6af-ad5b87b7d6b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 74 images in /content/drive/MyDrive/CVProject/\n",
            "\n",
            "Evaluating attack: Random Noise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Random Noise:  10%|â–ˆ         | 1/10 [00:00<00:06,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Random Noise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Random Noise:\n",
            "  Accuracy: 0.5595\n",
            "  False Positive Rate: 0.0856\n",
            "  False Negative Rate: 0.9730\n",
            "  Average Processing Time: 82.77 ms\n",
            "\n",
            "Evaluating attack: Targeted Shift\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Targeted Shift:  10%|â–ˆ         | 1/10 [00:00<00:04,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Targeted Shift: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Targeted Shift:\n",
            "  Accuracy: 0.5649\n",
            "  False Positive Rate: 0.1036\n",
            "  False Negative Rate: 0.9324\n",
            "  Average Processing Time: 68.55 ms\n",
            "\n",
            "Evaluating attack: Random Occlusion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Random Occlusion:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:02,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Random Occlusion: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Random Occlusion:\n",
            "  Accuracy: 0.5703\n",
            "  False Positive Rate: 0.1036\n",
            "  False Negative Rate: 0.9189\n",
            "  Average Processing Time: 99.85 ms\n",
            "\n",
            "Evaluating attack: Adversarial Example\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Adversarial Example:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:02,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image /content/drive/MyDrive/CVProject/000071_camera1.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Adversarial Example: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Adversarial Example:\n",
            "  Accuracy: 0.5811\n",
            "  False Positive Rate: 0.0766\n",
            "  False Negative Rate: 0.9324\n",
            "  Average Processing Time: 59.77 ms\n",
            "Results visualization saved to /content/drive/MyDrive/CVProject/output/evaluation_results.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}